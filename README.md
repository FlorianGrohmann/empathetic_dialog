# empathetic_dialog

use llama-7b as basemodel and train on the dataset, for inference use both our and the alpaca lora.
